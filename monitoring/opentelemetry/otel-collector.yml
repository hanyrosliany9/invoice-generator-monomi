# =============================================================================
# OPENTELEMETRY COLLECTOR CONFIGURATION
# APM for Monomi Finance - Indonesian Business Management System
# =============================================================================

# Receiver configuration - collect telemetry data
receivers:
  # OTLP receiver for application traces and metrics
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
        max_recv_msg_size: 4194304
        max_concurrent_streams: 100
      http:
        endpoint: 0.0.0.0:4318
        cors:
          allowed_origins:
            - "http://localhost:3000"  # Frontend
            - "http://localhost:5000"  # Backend
  
  # Prometheus receiver for existing metrics
  prometheus:
    config:
      scrape_configs:
        - job_name: 'monomi-backend'
          static_configs:
            - targets: ['host.docker.internal:5000']
          scrape_interval: 15s
          metrics_path: '/metrics'
        
        - job_name: 'monomi-frontend'
          static_configs:
            - targets: ['host.docker.internal:3000']
          scrape_interval: 30s
          metrics_path: '/metrics'
  
  # Jaeger receiver for legacy Jaeger traces
  jaeger:
    protocols:
      grpc:
        endpoint: 0.0.0.0:14250
      thrift_http:
        endpoint: 0.0.0.0:14268
      thrift_compact:
        endpoint: 0.0.0.0:6831
      thrift_binary:
        endpoint: 0.0.0.0:6832

  # Host metrics for system monitoring
  hostmetrics:
    collection_interval: 30s
    scrapers:
      cpu:
        metrics:
          system.cpu.utilization:
            enabled: true
      memory:
        metrics:
          system.memory.utilization:
            enabled: true
      disk:
        metrics:
          system.disk.io:
            enabled: true
      network:
        metrics:
          system.network.io:
            enabled: true
      filesystem:
        metrics:
          system.filesystem.utilization:
            enabled: true

# Processor configuration - process and enhance telemetry data
processors:
  # Batch processor for performance
  batch:
    timeout: 1s
    send_batch_size: 1024
    send_batch_max_size: 2048
  
  # Memory limiter to prevent OOM
  memory_limiter:
    limit_mib: 512
    spike_limit_mib: 128
    check_interval: 1s
  
  # Resource processor for Indonesian business context
  resource:
    attributes:
      - key: environment
        value: "production"
        action: upsert
      - key: service.namespace
        value: "monomi-finance"
        action: upsert
      - key: deployment.environment
        value: "production"
        action: upsert
      - key: business.region
        value: "indonesia"
        action: upsert
      - key: business.timezone
        value: "Asia/Jakarta"
        action: upsert
      - key: compliance.framework
        value: "ISO27001,NIST"
        action: upsert
  
  # Attributes processor for Indonesian business enrichment
  attributes:
    actions:
      # Add Indonesian business context to spans
      - key: business.country
        value: "Indonesia"
        action: upsert
      - key: business.currency
        value: "IDR"
        action: upsert
      - key: business.locale
        value: "id_ID"
        action: upsert
      - key: compliance.materai_threshold
        value: "5000000"
        action: upsert
  
  # Span processor for business workflow tracking
  span:
    name:
      # Rename spans for Indonesian business context
      from_attributes: ["http.route", "db.operation"]
      separator: ":"
    status:
      # Mark spans as error for business logic failures
      set_status_on_error: true

  # Probabilistic sampler for high-volume environments
  probabilistic_sampler:
    sampling_percentage: 10.0
    hash_seed: 22
  
  # Tail sampling for advanced sampling strategies
  tail_sampling:
    decision_wait: 30s
    num_traces: 50000
    expected_new_traces_per_sec: 100
    policies:
      # Always sample error traces
      - name: error_traces
        type: status_code
        status_code:
          status_codes: [ERROR]
      
      # Always sample Indonesian business critical operations
      - name: business_critical
        type: string_attribute
        string_attribute:
          key: business.operation
          values: ["invoice_create", "quotation_approve", "materai_check", "payment_process"]
      
      # Sample high-value transactions (>5M IDR)
      - name: high_value_transactions
        type: numeric_attribute
        numeric_attribute:
          key: business.amount_idr
          min_value: 5000000
      
      # Probabilistic sampling for normal operations
      - name: probabilistic
        type: probabilistic
        probabilistic:
          sampling_percentage: 5.0

# Exporter configuration - send telemetry data to backends
exporters:
  # Prometheus exporter for metrics
  prometheus:
    endpoint: "0.0.0.0:8889"
    namespace: "monomi"
    const_labels:
      environment: "production"
      service: "monomi-finance"
      region: "indonesia"
    send_timestamps: true
    metric_expiration: 180m
    enable_open_metrics: true
  
  # Jaeger exporter for distributed tracing
  jaeger:
    endpoint: jaeger:14250
    tls:
      insecure: true
    sending_queue:
      enabled: true
      num_consumers: 10
      queue_size: 1000
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s
  
  # Loki exporter for structured logs
  loki:
    endpoint: "http://loki:3100/loki/api/v1/push"
    tenant_id: "monomi-finance"
    labels:
      attributes:
        service.name: "service_name"
        service.version: "service_version"
        environment: "environment"
        business.country: "business_country"
    format: "json"
  
  # OTLP exporter for external observability platforms
  otlp:
    endpoint: "https://api.honeycomb.io:443"
    headers:
      "x-honeycomb-team": "${HONEYCOMB_API_KEY}"
    compression: gzip
    timeout: 10s
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s
  
  # File exporter for debugging and local development
  file:
    path: "/tmp/otel-traces.json"
    rotation:
      max_megabytes: 100
      max_days: 3
      max_backups: 3

# Extension configuration
extensions:
  # Health check extension
  health_check:
    endpoint: 0.0.0.0:13133
    path: "/health"
  
  # pprof for performance profiling
  pprof:
    endpoint: 0.0.0.0:1777
  
  # zpages for internal telemetry
  zpages:
    endpoint: 0.0.0.0:55679

# Service configuration - define pipelines
service:
  extensions: [health_check, pprof, zpages]
  
  pipelines:
    # Traces pipeline for distributed tracing
    traces:
      receivers: [otlp, jaeger]
      processors: [memory_limiter, resource, attributes, span, tail_sampling, batch]
      exporters: [jaeger, loki, file]
    
    # Metrics pipeline for application and business metrics
    metrics:
      receivers: [otlp, prometheus, hostmetrics]
      processors: [memory_limiter, resource, attributes, batch]
      exporters: [prometheus]
    
    # Logs pipeline for structured logging
    logs:
      receivers: [otlp]
      processors: [memory_limiter, resource, attributes, batch]
      exporters: [loki, file]

  # Telemetry configuration for the collector itself
  telemetry:
    logs:
      level: "info"
      development: false
      sampling:
        enabled: true
        tick: 10s
        initial: 10
        thereafter: 100
      encoding: "json"
      output_paths: ["stdout"]
      error_output_paths: ["stderr"]
      initial_fields:
        service: "otel-collector"
        environment: "production"
        region: "indonesia"
    
    metrics:
      level: detailed
      address: 0.0.0.0:8888
      readers:
        - periodic:
            interval: 30s
            timeout: 10s

    # Resource for collector telemetry
    resource:
      attributes:
        service.name: "otel-collector"
        service.version: "0.91.0"
        service.namespace: "monomi-finance"
        deployment.environment: "production"
        business.region: "indonesia"